{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ed244c08",
      "metadata": {
        "id": "ed244c08"
      },
      "source": [
        "# Training for Yolo8 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ee431253",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee431253",
        "outputId": "e3751d98-77c3-4a30-d33b-57504a362b29"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "15020e20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15020e20",
        "outputId": "e58e27c2-681b-4c59-fd4e-c1111f74b969"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ultralytics in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (8.3.127)\n",
            "Requirement already satisfied: numpy>=1.23.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (2.1.1)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (3.10.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (2.7.0+cu128)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (0.22.0+cu128)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (7.0.0)\n",
            "Requirement already satisfied: py-cpuinfo in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (2.2.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (0.13.2)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from ultralytics) (2.0.14)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
            "Requirement already satisfied: sympy>=1.13.3 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n",
            "Requirement already satisfied: networkx in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from torch>=1.8.0->ultralytics) (70.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: colorama in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "7b787c6a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kagglehub\n",
            "  Using cached kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: packaging in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from kagglehub) (6.0.2)\n",
            "Requirement already satisfied: requests in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests->kagglehub) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests->kagglehub) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from requests->kagglehub) (2025.4.26)\n",
            "Requirement already satisfied: colorama in e:\\thesis-model\\yolo-emotion-detection\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Using cached kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
            "Installing collected packages: kagglehub\n",
            "Successfully installed kagglehub-0.3.12\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install kagglehub"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2pY8ur0C8wAZ",
      "metadata": {
        "id": "2pY8ur0C8wAZ"
      },
      "source": [
        "## Import Ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "IDAfkfWC84d3",
      "metadata": {
        "id": "IDAfkfWC84d3"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81IlUM5d9HYC",
      "metadata": {
        "id": "81IlUM5d9HYC"
      },
      "source": [
        "## Download Dataset from kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "ZGe1ri5l9NZ8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGe1ri5l9NZ8",
        "outputId": "86c32b49-eee1-4e1b-e6cd-ea171886ec99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\thesis-model\\yolo-emotion-detection\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/aklimarimi/8-facial-expressions-for-yolo?dataset_version_number=4...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3.77G/3.77G [10:39<00:00, 6.33MB/s] "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\aklimarimi\\8-facial-expressions-for-yolo\\versions\\4\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"aklimarimi/8-facial-expressions-for-yolo\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dzunKuq87hT",
      "metadata": {
        "id": "4dzunKuq87hT"
      },
      "source": [
        "## Training for yolov8 (30 Epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bcaaa072",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcaaa072",
        "outputId": "b32a5434-512f-47d2-b57a-6ded46a6cb12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:02<00:00, 10.3MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transferred 355/355 items from pretrained weights\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "model = YOLO(\"yolov8s.yaml\").load(\"yolov8s.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83cfc43c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83cfc43c",
        "outputId": "dcbc18e4-eec4-4b84-81b4-1dfc283e5d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New https://pypi.org/project/ultralytics/8.3.134 available  Update with 'pip install -U ultralytics'\n",
            "Ultralytics 8.3.127  Python-3.12.8 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
            "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=32, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=True, cutmix=0.0, data=datasets/9 Facial Expressions you need/data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.2, mode=train, model=yolov8s.yaml, momentum=0.937, mosaic=1.0, multi_scale=False, name=train2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=yolov8s.pt, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\train2, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=5, warmup_momentum=0.8, weight_decay=0.001, workers=8, workspace=None\n",
            "Overriding model.yaml nc=80 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2119531  ultralytics.nn.modules.head.Detect           [9, [128, 256, 512]]          \n",
            "YOLOv8s summary: 129 layers, 11,139,083 parameters, 11,139,067 gradients, 28.7 GFLOPs\n",
            "\n",
            "Transferred 349/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 4.52.0 MB/s, size: 20.2 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning E:\\thesis-model\\new-yolo-emotion-detection\\datasets\\9 Facial Expressions you need\\train\\labels... 64864 images, 0 backgrounds, 0 corrupt: 100%|██████████| 64864/64864 [01:17<00:00, 832.17it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: E:\\thesis-model\\new-yolo-emotion-detection\\datasets\\9 Facial Expressions you need\\train\\labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 10.113.1 MB/s, size: 83.6 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning E:\\thesis-model\\new-yolo-emotion-detection\\datasets\\9 Facial Expressions you need\\valid\\labels... 1720 images, 0 backgrounds, 0 corrupt: 100%|██████████| 1720/1720 [00:03<00:00, 519.45it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: E:\\thesis-model\\new-yolo-emotion-detection\\datasets\\9 Facial Expressions you need\\valid\\labels.cache\n",
            "Plotting labels to runs\\detect\\train2\\labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.001), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1mruns\\detect\\train2\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/30      6.99G      1.188      2.343      1.623        101        640: 100%|██████████| 2027/2027 [07:25<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.27it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.439       0.52      0.496       0.33\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/30      6.72G     0.9944      1.593       1.44         89        640: 100%|██████████| 2027/2027 [07:19<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.41it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.555      0.616       0.63      0.435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/30      6.74G     0.9868      1.508      1.432        118        640: 100%|██████████| 2027/2027 [07:11<00:00,  4.69it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.643      0.618      0.687      0.497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/30      6.76G      0.987      1.481      1.427        105        640: 100%|██████████| 2027/2027 [07:05<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.635      0.661      0.713      0.526\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/30      6.74G      1.019      1.533      1.452         95        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.662      0.665      0.718      0.522\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/30      6.76G      1.016      1.519      1.447         97        640: 100%|██████████| 2027/2027 [07:03<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.684      0.693      0.741      0.549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/30      6.73G      0.971      1.426      1.412         99        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.705      0.715       0.77      0.583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/30      6.76G     0.9489      1.375      1.396         79        640: 100%|██████████| 2027/2027 [07:03<00:00,  4.79it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.714      0.708      0.782      0.594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/30      6.74G      0.927      1.328      1.379         84        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720       0.74      0.713      0.799      0.612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/30      6.76G     0.9141      1.301      1.367         97        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.738      0.751      0.812      0.624\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/30      6.73G     0.8962       1.27      1.356         74        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.754      0.758      0.818      0.632\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/30      6.76G     0.8885      1.249       1.35         79        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.39it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.772      0.749      0.826       0.64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/30      6.73G     0.8754      1.222      1.341        101        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.43it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.777      0.748      0.831      0.646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/30      6.76G     0.8654      1.196      1.331        115        640: 100%|██████████| 2027/2027 [07:05<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.777      0.747      0.833      0.646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/30      6.74G     0.8557      1.178      1.325         85        640: 100%|██████████| 2027/2027 [07:05<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.769      0.758      0.836       0.65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/30      6.76G     0.8473      1.155      1.319        112        640: 100%|██████████| 2027/2027 [07:05<00:00,  4.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.779      0.761      0.838      0.653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/30      7.02G      0.837      1.138      1.311         99        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.06it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.782      0.767      0.841      0.654\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/30      6.76G      0.826      1.111      1.303         92        640: 100%|██████████| 2027/2027 [07:13<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.789      0.764      0.841      0.656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/30      7.03G     0.8123      1.093      1.293         75        640: 100%|██████████| 2027/2027 [07:16<00:00,  4.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:09<00:00,  2.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.794      0.766      0.844      0.658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/30      6.76G     0.8044      1.073      1.289        115        640: 100%|██████████| 2027/2027 [07:19<00:00,  4.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.789       0.77      0.846      0.659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/30      7.03G     0.7633     0.7331       1.37         32        640: 100%|██████████| 2027/2027 [07:09<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:09<00:00,  2.75it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.778       0.78      0.849      0.663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/30      6.75G     0.7413     0.6944      1.348         32        640: 100%|██████████| 2027/2027 [07:10<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:09<00:00,  2.95it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.769       0.79      0.851      0.666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/30      7.02G     0.7268       0.66      1.334         32        640: 100%|██████████| 2027/2027 [07:11<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:09<00:00,  2.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.767      0.794      0.854      0.669\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/30      6.76G       0.71     0.6285      1.317         32        640: 100%|██████████| 2027/2027 [07:11<00:00,  4.70it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:09<00:00,  2.98it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.772      0.795      0.856      0.673\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/30      6.72G     0.6987        0.6      1.307         32        640: 100%|██████████| 2027/2027 [07:10<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.781      0.791      0.858      0.676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/30      6.75G     0.6871     0.5721      1.296         32        640: 100%|██████████| 2027/2027 [07:10<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.04it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.788      0.791      0.861      0.679\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/30      7.03G     0.6769     0.5531      1.289         32        640: 100%|██████████| 2027/2027 [07:08<00:00,  4.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:10<00:00,  2.62it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.786      0.797      0.863       0.68\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/30      6.76G     0.6669       0.53      1.278         32        640: 100%|██████████| 2027/2027 [07:10<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.13it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.791      0.796      0.866      0.683\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/30      7.03G     0.6599     0.5159      1.273         32        640: 100%|██████████| 2027/2027 [07:10<00:00,  4.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:10<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.789      0.802      0.868      0.684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/30      6.75G     0.6545     0.5095      1.267         31        640: 100%|██████████| 2027/2027 [07:04<00:00,  4.77it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:07<00:00,  3.42it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.794      0.798       0.87      0.686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "30 epochs completed in 3.659 hours.\n",
            "Optimizer stripped from runs\\detect\\train2\\weights\\last.pt, 22.5MB\n",
            "Optimizer stripped from runs\\detect\\train2\\weights\\best.pt, 22.5MB\n",
            "\n",
            "Validating runs\\detect\\train2\\weights\\best.pt...\n",
            "Ultralytics 8.3.127  Python-3.12.8 torch-2.7.0+cu128 CUDA:0 (NVIDIA GeForce RTX 3080, 10240MiB)\n",
            "YOLOv8s summary (fused): 72 layers, 11,129,067 parameters, 0 gradients, 28.5 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 27/27 [00:08<00:00,  3.03it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all       1720       1720      0.794      0.799       0.87      0.686\n",
            "                 angry        258        258      0.789      0.826      0.916      0.717\n",
            "              contempt         82         82      0.654      0.671      0.755      0.629\n",
            "               disgust        108        108      0.801      0.787       0.87      0.764\n",
            "                  fear        107        107      0.806      0.804      0.869      0.731\n",
            "                 happy        387        387      0.871      0.912      0.958      0.783\n",
            "               natural        172        172      0.684      0.663      0.747      0.559\n",
            "                   sad        312        312      0.812      0.811       0.89      0.679\n",
            "                sleepy         38         38      0.901      0.921      0.918      0.593\n",
            "             surprised        256        256      0.827      0.797      0.906      0.722\n",
            "Speed: 0.2ms preprocess, 1.6ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "results = model.train(data=\"datasets/9 Facial Expressions you need/data.yaml\", \n",
        "                        epochs=100, imgsz=640, device=0, save=True,\n",
        "                        plots=True, patience=10, save_period=10, batch=32, cos_lr=True, lr0=0.01, warmup_epochs=5, mosaic=1.0, mixup=0.2,\n",
        "                        close_mosaic=10, weight_decay=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "q7MIvXTzkFAD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7MIvXTzkFAD",
        "outputId": "67d1fb79-7fec-4e9d-f8ce-b2a5493a60c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "M_ZARn8_l-Gj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M_ZARn8_l-Gj",
        "outputId": "3469322a-6d76-409d-ced4-612615c41983"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/Thesis-Experiment/yolo/runs'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "# Source and destination paths\n",
        "src_path = '/content/runs'\n",
        "dst_path = '/content/drive/MyDrive/Thesis-Experiment/yolo/runs'\n",
        "\n",
        "# Copy everything\n",
        "shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "3D5Zu-fxmv8V",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3D5Zu-fxmv8V",
        "outputId": "33a25d68-e15a-4c6a-8835-487aefb0e2bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/val_batch2_labels.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/val_batch2_pred.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/confusion_matrix.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/val_batch1_labels.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/train_batch2.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/train_batch1.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/val_batch0_pred.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/train_batch0.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/results.csv\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/R_curve.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/train_batch40540.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/F1_curve.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/val_batch1_pred.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/P_curve.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/PR_curve.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/val_batch0_labels.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/labels_correlogram.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/confusion_matrix_normalized.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/train_batch40541.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/labels.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/train_batch40542.jpg\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/args.yaml\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/results.png\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/weights/last.pt\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/weights/epoch10.pt\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/weights/epoch20.pt\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/weights/best.pt\n",
            "/content/drive/MyDrive/Thesis-Experiment/yolo/runs/detect/train/weights/epoch0.pt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "for root, dirs, files in os.walk(dst_path):\n",
        "    for file in files:\n",
        "        print(os.path.join(root, file))\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "yolo-emotion-detection",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
